package com.scaleunlimited.wikiwords.flow;

import org.apache.log4j.Logger;

import cascading.flow.Flow;
import cascading.flow.FlowDef;
import cascading.operation.Debug;
import cascading.operation.DebugLevel;
import cascading.operation.aggregator.First;
import cascading.operation.expression.ExpressionFilter;
import cascading.operation.expression.ExpressionFunction;
import cascading.pipe.Each;
import cascading.pipe.Every;
import cascading.pipe.GroupBy;
import cascading.pipe.Pipe;
import cascading.pipe.assembly.CountBy;
import cascading.pipe.assembly.Rename;
import cascading.pipe.assembly.Retain;
import cascading.pipe.assembly.Unique;
import cascading.tap.SinkMode;
import cascading.tap.Tap;
import cascading.tuple.Fields;

import com.scaleunlimited.cascading.BasePath;
import com.scaleunlimited.cascading.BasePlatform;
import com.scaleunlimited.wikiwords.WorkingConfig;
import com.scaleunlimited.wikiwords.datum.WikiTermDatum;
import com.scaleunlimited.wikiwords.tools.AnalyzeTermsTool.AnalyzeTermsOptions;

public class AnalyzeTermsFlow {
    private static final Logger LOGGER = Logger.getLogger(AnalyzeTermsFlow.class);

    public AnalyzeTermsFlow() {
        // TODO Auto-generated constructor stub
    }
    
    public static Flow createFlow(AnalyzeTermsOptions options) throws Exception {
        
        // We're reading in files generated by GenerateTermsFlow, which contain WikiTermDatum records
        
        BasePlatform platform = options.getPlatform(AnalyzeTermsFlow.class);
        FlowDef flowDef = new FlowDef()
            .setName("analyze terms")
            .setDebugLevel(options.isDebug() ? DebugLevel.VERBOSE : DebugLevel.NONE);
        
        BasePath inputPath = options.getWorkingSubdirPath(WorkingConfig.TERMS_SUBDIR_NAME);
        Tap sourceTap = platform.makeTap(platform.makeBinaryScheme(WikiTermDatum.FIELDS), inputPath, SinkMode.KEEP);
        Pipe p = new Pipe("terms");
        flowDef.addSource(p, sourceTap);
        
        // Calculate the DF for each term.
        /*
        Pipe termDF = new Pipe("term DF", p);
        termDF = new Retain(termDF, new Fields(WikiTermDatum.TERM_FN, WikiTermDatum.ARTICLE_NAME_FN));
        termDF = new Unique(termDF, new Fields(WikiTermDatum.TERM_FN, WikiTermDatum.ARTICLE_NAME_FN));
        termDF = new CountBy(termDF, new Fields(WikiTermDatum.TERM_FN), new Fields("num_articles"));
        // termDF = new Each(termDF, DebugLevel.VERBOSE, new Debug("docs per term", true));
        
        termDF = new GroupBy(termDF, Fields.NONE, new Fields("num_articles"), true);
        termDF = new Each(termDF, new Fields("num_articles"), new ExpressionFunction(new Fields("df"), "(float)num_articles / " + options.getTotalArticles(), Float.class), Fields.SWAP);
        Tap termDFSink = platform.makeTap(platform.makeTextScheme(), options.getWorkingSubdirPath(WorkingConfig.TERMDF_SUBDIR_NAME), SinkMode.REPLACE);
        flowDef.addTailSink(termDF, termDFSink);
        */
        
        // Calculate the TF*IDF value for term/article ref pairs.
        Pipe termTFIDF = new Pipe("term TF*IDF pipe", p);
        termTFIDF = new Retain(termTFIDF, new Fields(WikiTermDatum.TERM_FN, WikiTermDatum.ARTICLE_REF_FN, WikiTermDatum.TERM_DISTANCE_FN));
        termTFIDF = new Each(termTFIDF, new Fields(WikiTermDatum.TERM_DISTANCE_FN), new ExpressionFunction(new Fields(TfIdfAssembly.TERM_COUNT_FN), "Math.max(1, 10-$0)", Integer.class), Fields.SWAP);
        termTFIDF = new Each(termTFIDF, new Fields(TfIdfAssembly.TERM_COUNT_FN), new ExpressionFilter("$0 == 0", Integer.class));
        
        termTFIDF = new Rename( termTFIDF,
                                new Fields(WikiTermDatum.TERM_FN, WikiTermDatum.ARTICLE_REF_FN),
                                new Fields(TfIdfAssembly.TERM_FN, TfIdfAssembly.DOC_FN));
        
        termTFIDF = new TfIdfAssembly(termTFIDF);

        // Group by term sort by score, take the top N, and reorder so terms are first
        termTFIDF = new GroupBy(termTFIDF, new Fields(TfIdfAssembly.TERM_FN), new Fields(TfIdfAssembly.TF_IDF_FN), true);
        termTFIDF = new Every(termTFIDF, new First(options.getTopArticleLimit()), Fields.RESULTS);
        termTFIDF = new Retain(termTFIDF, new Fields(TfIdfAssembly.TERM_FN, TfIdfAssembly.DOC_FN, TfIdfAssembly.TF_IDF_FN));
        
        BasePath outputPath = options.getWorkingSubdirPath(WorkingConfig.TERM_SCORES_SUBDIR_NAME);
        Tap sinkTap = platform.makeTap(platform.makeTextScheme(), outputPath, SinkMode.REPLACE);
        flowDef.addTailSink(termTFIDF, sinkTap);

        return platform.makeFlowConnector().connect(flowDef);
    }

}
