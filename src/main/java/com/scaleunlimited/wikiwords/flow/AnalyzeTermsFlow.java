package com.scaleunlimited.wikiwords.flow;

import java.io.DataInput;
import java.io.DataInputStream;
import java.io.InputStream;
import java.util.regex.Pattern;

import org.apache.log4j.Logger;

import cascading.flow.Flow;
import cascading.flow.FlowDef;
import cascading.flow.FlowProcess;
import cascading.operation.BaseOperation;
import cascading.operation.Debug;
import cascading.operation.DebugLevel;
import cascading.operation.Function;
import cascading.operation.FunctionCall;
import cascading.operation.OperationCall;
import cascading.operation.aggregator.First;
import cascading.operation.expression.ExpressionFilter;
import cascading.operation.expression.ExpressionFunction;
import cascading.pipe.CoGroup;
import cascading.pipe.Each;
import cascading.pipe.Every;
import cascading.pipe.GroupBy;
import cascading.pipe.Pipe;
import cascading.pipe.assembly.Rename;
import cascading.pipe.assembly.Retain;
import cascading.pipe.assembly.SumBy;
import cascading.tap.SinkMode;
import cascading.tap.Tap;
import cascading.tuple.Fields;
import cascading.tuple.Tuple;
import cascading.tuple.TupleEntry;

import com.scaleunlimited.cascading.BasePath;
import com.scaleunlimited.cascading.BasePlatform;
import com.scaleunlimited.cascading.LoggingFlowProcess;
import com.scaleunlimited.wikiwords.CategoryGraph;
import com.scaleunlimited.wikiwords.WorkingConfig;
import com.scaleunlimited.wikiwords.datum.WikiCategoryDatum;
import com.scaleunlimited.wikiwords.datum.WikiTermDatum;
import com.scaleunlimited.wikiwords.tools.AnalyzeTermsTool.AnalyzeTermsOptions;

public class AnalyzeTermsFlow {
    private static final Logger LOGGER = Logger.getLogger(AnalyzeTermsFlow.class);
    private static final Fields TERM_CATEGORY_FIELDS = new Fields(TfIdfAssembly.TERM_FN, WikiCategoryDatum.CATEGORY_FN, TfIdfAssembly.TF_IDF_FN);

    public static Flow createFlow(AnalyzeTermsOptions options) throws Exception {
        
        BasePlatform platform = options.getPlatform(AnalyzeTermsFlow.class);
        FlowDef flowDef = new FlowDef()
            .setName("analyze terms")
            .setDebugLevel(options.isDebugLogging() ? DebugLevel.VERBOSE : DebugLevel.NONE);
        
        // We're reading in files generated by GenerateTermsFlow, which contain WikiTermDatum records
        BasePath termPath = options.getWorkingSubdirPath(WorkingConfig.TERMS_SUBDIR_NAME);
        Tap termTap = platform.makeTap(platform.makeBinaryScheme(WikiTermDatum.FIELDS), termPath, SinkMode.KEEP);
        Pipe terms = new Pipe("terms");
        terms = new Each(terms, DebugLevel.VERBOSE, new Debug("terms", true));
        flowDef.addSource(terms, termTap);
        
        BasePath categoryPath = options.getWorkingSubdirPath(WorkingConfig.CATEGORIES_SUBDIR_NAME);
        Tap categoryTap = platform.makeTap(platform.makeBinaryScheme(WikiCategoryDatum.FIELDS), categoryPath, SinkMode.KEEP);
        Pipe categories = new Pipe("categories");
        categories = new Each(categories, DebugLevel.VERBOSE, new Debug("categories", true));
        flowDef.addSource(categories, categoryTap);
        
        // Calculate the TF*IDF value for term/article ref pairs.
        Pipe termTFIDF = new Pipe("term TF*IDF pipe", terms);
        termTFIDF = new Retain(termTFIDF, new Fields(WikiTermDatum.TERM_FN, WikiTermDatum.ARTICLE_REF_FN, WikiTermDatum.TERM_DISTANCE_FN));
        // Our "term count" could be based on distance (e.g. Math.max(1, 10-$0)), or a step function (e.g. ($0 > 10 ? 0 : 1))
        termTFIDF = new Each(termTFIDF, new Fields(WikiTermDatum.TERM_DISTANCE_FN), new ExpressionFunction(new Fields(TfIdfAssembly.TERM_COUNT_FN), "($0 > 10 ? 0 : 1)", Integer.class), Fields.SWAP);
        termTFIDF = new Each(termTFIDF, new Fields(TfIdfAssembly.TERM_COUNT_FN), new ExpressionFilter("$0 == 0", Integer.class));
        
        termTFIDF = new Rename( termTFIDF,
                                new Fields(WikiTermDatum.TERM_FN, WikiTermDatum.ARTICLE_REF_FN),
                                new Fields(TfIdfAssembly.TERM_FN, TfIdfAssembly.DOC_FN));
        
        termTFIDF = new TfIdfAssembly(termTFIDF);

        // If the number of times the term occurs with the doc is too low, strip it out.
        if (options.getMinArticleRefs() > 0) {
            termTFIDF = new Each( termTFIDF,
                               new Fields(TfIdfAssembly.TERM_COUNT_PER_DOC_FN),
                               new ExpressionFilter(String.format("$0 < %d",  options.getMinArticleRefs()), Integer.class));
        }
        
        // See if the score is below a threshold
        if (options.getMinArticleScore() > 0.0f) {
            termTFIDF = new Each(   termTFIDF,
                                    new Fields(TfIdfAssembly.TF_IDF_FN),
                                    new ExpressionFilter(String.format("$0 < %f", options.getMinArticleScore()), Float.class));
        }
        termTFIDF = new Each(termTFIDF, DebugLevel.VERBOSE, new Debug("scored terms", true));

        // Group by term, sort by score, take the top N, and reorder so terms are first
        Pipe topTerms = new GroupBy("top terms", termTFIDF, new Fields(TfIdfAssembly.TERM_FN), new Fields(TfIdfAssembly.TF_IDF_FN), true);
        topTerms = new Every(topTerms, new First(options.getTopArticleLimit()), Fields.RESULTS);
        topTerms = new Retain(topTerms, new Fields(TfIdfAssembly.TERM_FN, TfIdfAssembly.DOC_FN, TfIdfAssembly.TF_IDF_FN, TfIdfAssembly.TERM_COUNT_PER_DOC_FN));
        // topTerms = new Each(topTerms, DebugLevel.VERBOSE, new Debug("top terms", true));

        BasePath topTermsPath = options.getWorkingSubdirPath(WorkingConfig.TERM_SCORES_SUBDIR_NAME);
        Tap topTermsSink = platform.makeTap(platform.makeTextScheme(), topTermsPath, SinkMode.REPLACE);
        flowDef.addTailSink(topTerms, topTermsSink);

        // We're going to also join the article/category data with the article/term/score/count data, so we get term/category/score (we drop count)
        Pipe termCategoryPipe = new CoGroup("term to category",
                                            categories, new Fields(WikiCategoryDatum.ARTICLE_NAME_FN),
                                            termTFIDF, new Fields(TfIdfAssembly.DOC_FN));
        // We've got WikiCategoryDatum.ARTICLE_NAME_FN, WikiCategoryDatum.CATEGORY_FN, TfIdfAssembly.DOC_FN, TfIdfAssembly.TERM_FN, TfIdfAssembly.TF_IDF_FN, TfIdfAssembly.TERM_COUNT_PER_DOC_FN
        termCategoryPipe = new Retain(termCategoryPipe, TERM_CATEGORY_FIELDS);
        termCategoryPipe = new Each(termCategoryPipe, DebugLevel.VERBOSE, new Debug("term-category (preexpansion)", true));

        // Expand categories (if requested), and then sum term x category
        if (options.getCategoryGraphFilename() != null) {
            // TODO support max depth option for category depth
            termCategoryPipe = new Each(termCategoryPipe,
                                        new Fields(WikiCategoryDatum.CATEGORY_FN), 
                                        new ExpandCategory(platform, options.getCategoryGraphFilename(), 50),
                                        Fields.SWAP);
        }
        
        termCategoryPipe = new SumBy(termCategoryPipe, new Fields(TfIdfAssembly.TERM_FN, WikiCategoryDatum.CATEGORY_FN), new Fields(TfIdfAssembly.TF_IDF_FN), new Fields("category_score"), Float.class);
        termCategoryPipe = new Each(termCategoryPipe, DebugLevel.VERBOSE, new Debug("term-category (prefiltered)", true));

        // Filter if requested
        if (options.getMinCategoryScore() > 0.0f) {
            termCategoryPipe = new Each(termCategoryPipe,
                                        new Fields("category_score"),
                                        new ExpressionFilter(String.format("$0 < %f", options.getMinCategoryScore()), Float.class));
        }

        BasePath termCategoryPath = options.getWorkingSubdirPath(WorkingConfig.TERM_CATEGORIES_SUBDIR_NAME);
        Tap termCategorySink = platform.makeTap(platform.makeTextScheme(), termCategoryPath, SinkMode.REPLACE);
        flowDef.addTailSink(termCategoryPipe, termCategorySink);
        
        return platform.makeFlowConnector().connect(flowDef);
    }

    
    /**
     * Expand the passed category to all parents.
     *
     */
    @SuppressWarnings("serial")
    public static class ExpandCategory extends BaseOperation<Void> implements Function<Void> {

        private static final Pattern[] FILTERED_CATNAMES = new Pattern[] {
            // Wikipedia categories named after landforms
            // Wikipedia administration
            Pattern.compile("Wikipedia .+"),
            
            // 1917 in military history
            // 1930s
            // Conflicts in 2012
            Pattern.compile(".*\\d\\d\\d\\d.*"),
            
            // 16th century by continent
            Pattern.compile("\\d{1,2}(st|nd|rd|th).+"),
            
            // {{CURRENTYEAR}}
            Pattern.compile("\\{\\{.+\\}\\}")
        };
        
        private String _categoryGraphPathname;
        private int _maxDepth;
        private BasePlatform _platform;
        
        private transient LoggingFlowProcess _flowProcess;
        private transient CategoryGraph _categoryGraph;
        private transient Tuple _result;
        
        public ExpandCategory(BasePlatform platform, String categoryGraphPathname, int maxDepth) {
            super(1, new Fields(WikiCategoryDatum.CATEGORY_FN));
            
            _platform = platform;
            _categoryGraphPathname = categoryGraphPathname;
            _maxDepth = maxDepth;
        }

        @Override
        public void prepare(FlowProcess flowProcess, OperationCall<Void> operationCall) {
            super.prepare(flowProcess, operationCall);
            _flowProcess = new LoggingFlowProcess<>(flowProcess);
            _result = Tuple.size(1);
            
            _categoryGraph = new CategoryGraph();
            try (InputStream is = _platform.makePath(_categoryGraphPathname).openInputStream()) {
                DataInput in = new DataInputStream(is);
                _categoryGraph.readFields(in);
            } catch (Exception e) {
                throw new RuntimeException("Error opening category graph file", e);
            }
        }

        @Override
        public void operate(FlowProcess flowProcess, FunctionCall<Void> functionCall) {
            TupleEntry te = functionCall.getArguments();
            
            String categoryName = te.getString(0);
            if (!_categoryGraph.exists(categoryName)) {
                LOGGER.warn("Got unknown category: " + categoryName);
                return;
            }
            
            for (String catName : _categoryGraph.getTree(categoryName, _maxDepth)) {
                if (!filterCategory(catName)) {
                    _result.setString(0, catName);
                    functionCall.getOutputCollector().add(_result);
                }
            }
        }

        protected boolean filterCategory(String catName) {
            for (Pattern p : FILTERED_CATNAMES) {
                if (p.matcher(catName).matches()) {
                    return true;
                }
            }
            
            return false;
        }
    }
    

}
